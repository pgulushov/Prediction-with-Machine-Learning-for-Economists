{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c39298a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import brier_score_loss, roc_curve, auc, confusion_matrix, roc_auc_score, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from plotnine import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e1af41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r\"C:\\Users\\99450\\Desktop\\cs_bisnode_panel_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecd7c4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_results(y_true, y_pred):\n",
    "\n",
    "    # Regression metrics\n",
    "    explained_variance=metrics.explained_variance_score(y_true, y_pred)\n",
    "    mean_absolute_error=metrics.mean_absolute_error(y_true, y_pred) \n",
    "    mse=metrics.mean_squared_error(y_true, y_pred) \n",
    "    median_absolute_error=metrics.median_absolute_error(y_true, y_pred)\n",
    "    r2=metrics.r2_score(y_true, y_pred)\n",
    "\n",
    "    print('explained_variance: ', round(explained_variance,4))    \n",
    "    print('r2: ', round(r2,4))\n",
    "    print('MAE: ', round(mean_absolute_error,4))\n",
    "    print('MSE: ', round(mse,4))\n",
    "    print('RMSE: ', round(np.sqrt(mse),4))\n",
    "    \n",
    "def coef_matrix(X, model):\n",
    "\n",
    "    coef_matrix = pd.concat([pd.DataFrame(X.columns),pd.DataFrame(np.transpose(model.coef_))], axis = 1)\n",
    "    coef_matrix.columns = ['variable', 'coefficient']\n",
    "    coef_matrix = coef_matrix.append({'variable': 'Intercept', 'coefficient': np.asscalar(model.intercept_)}, ignore_index=True)\n",
    "    return(coef_matrix)\n",
    "\n",
    "def cv_summary(lambdas, C_values, model):\n",
    "    d = {'lambdas': lambdas, 'C_values': C_values, 'mean_cv_score': model.scores_[1].mean(axis = 0)}\n",
    "    return(pd.DataFrame(data=d))\n",
    "\n",
    "def create_roc_plot(y_true, y_pred):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    all_coords = pd.DataFrame({\n",
    "        'fpr': fpr,\n",
    "        'tpr': tpr,\n",
    "        'thresholds': thresholds\n",
    "    })\n",
    "    \n",
    "    plot = ggplot(all_coords, aes(x = 'fpr', y = 'tpr')) \\\n",
    "        + geom_line(color=color[0], size = 0.7) \\\n",
    "        + geom_area(position = 'identity', fill = 'mediumaquamarine', alpha = 0.3) \\\n",
    "        + xlab(\"False Positive Rate (1-Specifity)\") \\\n",
    "        + ylab(\"True Positive Rate (Sensitivity)\") \\\n",
    "        + geom_abline(intercept = 0, slope = 1,  linetype = \"dotted\", color = \"black\") \\\n",
    "        + scale_y_continuous(limits = (0, 1), breaks = seq(0, 1, .1), expand = (0, 0.01)) \\\n",
    "        + scale_x_continuous(limits = (0, 1), breaks = seq(0, 1, .1), expand = (0.01, 0)) \\\n",
    "        + theme_bw()\n",
    "    return(plot)\n",
    "\n",
    "def sigmoid_array(x):\n",
    "    return(1 / (1 + np.exp(-x)))\n",
    "\n",
    "def generate_fold_prediction(model, X, fold, param_index):\n",
    "    fold_coef = model.coefs_paths_[1][fold,param_index,:]\n",
    "    return(sigmoid_array(np.dot(X, np.transpose(fold_coef)[:-1]) +  np.transpose(fold_coef)[-1]))\n",
    "\n",
    "def create_loss_plot(all_coords, optimal_threshold, curr_exp_loss):\n",
    "    all_coords_copy = all_coords.copy()\n",
    "    all_coords_copy['loss'] = (all_coords_copy.false_pos*FP + all_coords_copy.false_neg*FN)/all_coords_copy.n\n",
    "    \n",
    "    t = optimal_threshold\n",
    "    l = curr_exp_loss\n",
    "    \n",
    "    plot = ggplot(all_coords_copy, aes(x = 'thresholds', y = 'loss')) + \\\n",
    "        geom_line(color=color[0], size=0.7) + \\\n",
    "        scale_x_continuous(breaks = seq(0, 1.1, by = 0.1)) + \\\n",
    "        coord_cartesian(xlim=(0,1))+ \\\n",
    "        geom_vline(xintercept = t , color = color[0] ) + \\\n",
    "        annotate(geom = \"text\", x = t - 0.01, y= max(all_coords_copy.loss) - 0.4,\n",
    "                 label=\"best threshold: \" + str(round(t,2)),\n",
    "                 colour=color[1], angle=90, size = 7) +\\\n",
    "        annotate(geom = \"text\", x = t + 0.06, y= l,\\\n",
    "                 label= str(round(l, 2)), size = 7) +\\\n",
    "        theme_bw()\n",
    "    return(plot)\n",
    "\n",
    "\n",
    "def create_roc_plot_with_optimal(all_coords, optimal_threshold):\n",
    "    all_coords_copy = all_coords.copy()\n",
    "    all_coords_copy[\"sp\"] = 1 - all_coords_copy.true_neg / all_coords_copy.neg\n",
    "    all_coords_copy[\"se\"] = all_coords_copy.true_pos / all_coords_copy.pos\n",
    "\n",
    "    best_coords = all_coords_copy[all_coords_copy.thresholds == optimal_threshold]\n",
    "    sp = best_coords.sp.values[0]\n",
    "    se = best_coords.se.values[0]\n",
    "\n",
    "    plot = (\n",
    "        ggplot(all_coords_copy, aes(x=\"sp\", y=\"se\"))\n",
    "        + geom_line(color=color[0], size=0.7)\n",
    "        + scale_y_continuous(breaks=seq(0, 1.1, by=0.1))\n",
    "        + scale_x_continuous(breaks=seq(0, 1.1, by=0.1))\n",
    "        + geom_point(data=pd.DataFrame({\"sp\": [sp], \"se\": [se]}))\n",
    "        + annotate(\n",
    "            geom=\"text\",\n",
    "            x=sp,\n",
    "            y=se + 0.03,\n",
    "            label=str(round(sp, 2)) + \", \" + str(round(se, 2)),\n",
    "            size=7,\n",
    "        )\n",
    "        + geom_area(position=\"identity\", fill=\"mediumaquamarine\", alpha=0.3)\n",
    "        + xlab(\"False Positive Rate (1-Specifity)\")\n",
    "        + ylab(\"True Positive Rate (Sensitivity)\")\n",
    "        + geom_abline(intercept=0, slope=1, linetype=\"dotted\", color=\"black\")\n",
    "        + theme_bw()\n",
    "    )\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de9475f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawvars = [\"curr_assets\", \"curr_liab\", \"extra_exp\", \"extra_inc\", \"extra_profit_loss\", \"fixed_assets\",\n",
    "              \"inc_bef_tax\", \"intang_assets\", \"inventories\", \"liq_assets\", \"material_exp\", \"personnel_exp\",\n",
    "              \"profit_loss_year\", \"sales\", \"share_eq\", \"subscribed_cap\"]\n",
    "qualityvars = [\"balsheet_flag\", \"balsheet_length\", \"balsheet_notfullyear\"]\n",
    "engvar = [\"total_assets_bs\", \"fixed_assets_bs\", \"liq_assets_bs\", \"curr_assets_bs\",\n",
    "            \"share_eq_bs\", \"subscribed_cap_bs\", \"intang_assets_bs\", \"extra_exp_pl\",\n",
    "            \"extra_inc_pl\", \"extra_profit_loss_pl\", \"inc_bef_tax_pl\", \"inventories_pl\",\n",
    "            \"material_exp_pl\", \"profit_loss_year_pl\", \"personnel_exp_pl\"]\n",
    "engvar2 = [\"extra_profit_loss_pl_quad\", \"inc_bef_tax_pl_quad\",\n",
    "             \"profit_loss_year_pl_quad\", \"share_eq_bs_quad\"]\n",
    "engvar3=[]\n",
    "for col in data.columns:\n",
    "    if col.endswith('flag_low') or col.endswith('flag_high') or col.endswith('flag_error') or col.endswith('flag_zero'):\n",
    "        engvar3.append(col)\n",
    "\n",
    "\n",
    "d1 =  [\"d1_sales_mil_log_mod\", \"d1_sales_mil_log_mod_sq\",\n",
    "         \"flag_low_d1_sales_mil_log\", \"flag_high_d1_sales_mil_log\"]\n",
    "hr = [\"female\", \"ceo_age\", \"flag_high_ceo_age\", \"flag_low_ceo_age\",\n",
    "        \"flag_miss_ceo_age\", \"ceo_count\", \"labor_avg_mod\",\n",
    "        \"flag_miss_labor_avg\", \"foreign_management\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "031908f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creat dummy columns from category variables and drop first level\n",
    "ind2_catmat = patsy.dmatrix(\"0 + C(ind2_cat)\",data, return_type=\"dataframe\")\n",
    "ind2_catmat = ind2_catmat.drop(['C(ind2_cat)[26.0]'], axis=1)\n",
    "\n",
    "m_region_locmat = patsy.dmatrix(\"0 + C(m_region_loc)\",data, return_type=\"dataframe\")\n",
    "m_region_locmat = m_region_locmat.drop(['C(m_region_loc)[Central]'], axis=1)\n",
    "\n",
    "urban_mmat = patsy.dmatrix(\"0 + C(urban_m)\",data, return_type=\"dataframe\")\n",
    "urban_mmat = urban_mmat.drop(['C(urban_m)[1.0]'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a025142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X1\n",
    "basevars = data[[\"sales_mil_log\", \"sales_mil_log_sq\", \"d1_sales_mil_log_mod\", \"profit_loss_year_pl\"]]\n",
    "X1 = pd.concat([basevars, ind2_catmat], axis=1)\n",
    "# Define X2\n",
    "X2additional_vars = data[[\"fixed_assets_bs\", \"share_eq_bs\",\"curr_liab_bs\", \"curr_liab_bs_flag_high\", \\\n",
    "                          \"curr_liab_bs_flag_error\",  \"age\", \"foreign_management\"]]\n",
    "X2 = pd.concat([X1, X2additional_vars], axis=1)\n",
    "# Define X3\n",
    "firm = pd.concat([data[[\"age\", \"age2\", \"new\"]], ind2_catmat, m_region_locmat, urban_mmat], axis=1)\n",
    "X3 = pd.concat([data[[\"sales_mil_log\", \"sales_mil_log_sq\"] + engvar + d1], firm], axis=1)\n",
    "# Define X4\n",
    "X4 = pd.concat([data[[\"sales_mil_log\", \"sales_mil_log_sq\"] + engvar + d1 \\\n",
    "                                 + engvar2 + engvar3 + hr + qualityvars], firm], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a75a5e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X5\n",
    "#Creat matrix for interactions1 variables\n",
    "int1mat = patsy.dmatrix(\"0 + C(ind2_cat):age + C(ind2_cat):age2 + C(ind2_cat):d1_sales_mil_log_mod \\\n",
    "                + C(ind2_cat):sales_mil_log + C(ind2_cat):ceo_age + C(ind2_cat):foreign_management \\\n",
    "                + C(ind2_cat):female + C(ind2_cat):C(urban_m) + C(ind2_cat):labor_avg_mod\", data, return_type=\"dataframe\")\n",
    "#Drop first level to get k-1 dummies out of k categorical levels \n",
    "for col in int1mat.columns:\n",
    "    if col.startswith('C(ind2_cat)[26.0]') or col.endswith('C(urban_m)[1.0]'):\n",
    "        int1mat = int1mat.drop([col], axis=1)\n",
    "        \n",
    "#Creat matrix for interactions2 variables        \n",
    "int2mat = patsy.dmatrix(\"0 + sales_mil_log:age + sales_mil_log:female + sales_mil_log:profit_loss_year_pl \\\n",
    "                + sales_mil_log:foreign_management\", data, return_type=\"dataframe\")\n",
    "X5 = pd.concat([X4, int1mat, int2mat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f8412ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define logitvars for LASSO\n",
    "logitvars = pd.concat([X4, int1mat, int2mat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f91ba64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define rfvars for RF (no interactions, no modified features)\n",
    "rfvars  = pd.concat([data[[\"sales_mil\", \"d1_sales_mil_log\"] + rawvars + hr + qualityvars], firm], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b47ff6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32c4314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check simplest model X1\n",
    "ols_modelx1 = LinearRegression().fit(X1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c9e89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_results(y, ols_modelx1.predict(X1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ac4dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_matrix(X1, ols_modelx1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a695c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_modelx1 = LogisticRegression(solver=\"newton-cg\",max_iter=1000, penalty=\"none\").fit(X1, y)\n",
    "regression_results(y, glm_modelx1.predict(X1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7062aa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_matrix(X1, glm_modelx1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f76b63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model X2\n",
    "glm_modelx2 = LogisticRegression(solver=\"newton-cg\", max_iter=1000, penalty=\"none\").fit(X2, y)\n",
    "regression_results(y, glm_modelx2.predict(X2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c392e5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mx2 = sm.Logit(y,sm.add_constant(X2)).fit().get_margeff()\n",
    "mx2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe228c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model is X4 (all vars, but no interactions) -------------------------------------------------------\n",
    "ols_model = LinearRegression().fit(X4, y)\n",
    "regression_results(y, ols_model.predict(X4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cf50f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_model = LogisticRegression(solver=\"newton-cg\",max_iter=1000, penalty=\"none\").fit(X4, y)\n",
    "regression_results(y, glm_model.predict(X4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceee502",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_matrix(X4, glm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd418597",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = sm.Logit(y,sm.add_constant(X4)).fit().get_margeff()\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a71d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_train, index_holdout = train_test_split(\n",
    "    data.index.values, train_size=round(0.8 * len(data.index)), random_state=42\n",
    ")\n",
    "\n",
    "y_train = y.iloc[index_train]\n",
    "y_holdout = y.iloc[index_holdout]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e646bfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total\")\n",
    "print(data[\"default\"].value_counts(normalize=True))\n",
    "print(\"Train\")\n",
    "print(data.iloc[index_train][\"default\"].value_counts(normalize=True))\n",
    "print(\"Holdout\")\n",
    "print(data.iloc[index_holdout][\"default\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f137cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0b086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no regularisation needed so setting the paremeter to very high value\n",
    "C_value_logit=[1e20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37519fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logit Models ----------------------------------------------\n",
    "logit_model_vars = [\n",
    "    X1.iloc[index_train],\n",
    "    X2.iloc[index_train],\n",
    "    X3.iloc[index_train],\n",
    "    X4.iloc[index_train],\n",
    "    X5.iloc[index_train],\n",
    "]\n",
    "\n",
    "logit_models = dict()\n",
    "CV_RMSE_folds = dict()\n",
    "\n",
    "for i in range(len(logit_model_vars)):\n",
    "    LRCV_brier = LogisticRegressionCV(\n",
    "        Cs=C_value_logit,\n",
    "        cv=k,\n",
    "        refit=True,\n",
    "        scoring=\"neg_brier_score\",\n",
    "        solver=\"newton-cg\",\n",
    "        tol=1e-7,\n",
    "        random_state=42,\n",
    "    )\n",
    "    logit_models[\"X\" + str(i + 1)] = LRCV_brier.fit(logit_model_vars[i], y_train)\n",
    "    # Calculate RMSE on test for each fold\n",
    "    CV_RMSE_folds[\"X\" + str(i + 1)] = np.sqrt(\n",
    "        -1 * (logit_models[\"X\" + str(i + 1)].scores_[1])\n",
    "    ).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19e5ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_logitvars = pd.DataFrame(\n",
    "    StandardScaler().fit_transform(logitvars.iloc[index_train])\n",
    ")\n",
    "normalized_logitvars.columns = logitvars.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bba863",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = list(10 ** np.arange(-1, -4.01, -1 / 3))\n",
    "n_obs = normalized_logitvars.shape[0] * 4 / 5\n",
    "C_values = [1 / (l * n_obs) for l in lambdas]\n",
    "\n",
    "logLasso = LogisticRegressionCV(\n",
    "    Cs=C_values,\n",
    "    penalty=\"l1\",\n",
    "    cv=k,\n",
    "    refit=True,\n",
    "    scoring=\"accuracy\",\n",
    "    solver=\"liblinear\",\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28abe660",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_models[\"LASSO\"] = logLasso.fit(normalized_logitvars, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5900b8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lambda = cv_summary_lasso.sort_values(\"mean_cv_score\", ascending=False).iloc[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b560e5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_matrix(normalized_logitvars, logit_models[\"LASSO\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fe09bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refit with negative brier score so we have RMSE values for the same cv split\n",
    "logLasso_brier = LogisticRegressionCV(\n",
    "    Cs=C_values,\n",
    "    penalty=\"l1\",\n",
    "    cv=k,\n",
    "    refit=True,\n",
    "    scoring=\"neg_brier_score\",\n",
    "    solver=\"liblinear\",\n",
    "    random_state=42,\n",
    ")\n",
    "logLasso_brier_fitted = logLasso_brier.fit(normalized_logitvars, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524e4c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, l in enumerate(lambdas):\n",
    "    if l == best_lambda:\n",
    "        best_lambda_i = i\n",
    "        CV_RMSE_folds[\"LASSO\"] = np.sqrt(\n",
    "            -1 * (logLasso_brier_fitted.scores_[1][:, i])\n",
    "        ).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bf9a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate AUC for each folds --------------------------------\n",
    "CV_AUC_folds = dict()\n",
    "\n",
    "# refit logit models with AUC so we have AUC values for the same cv split\n",
    "for i in range(len(logit_model_vars)):\n",
    "    LRCV_auc = LogisticRegressionCV(\n",
    "        Cs=C_value_logit,\n",
    "        cv=k,\n",
    "        refit=True,\n",
    "        scoring=\"roc_auc\",\n",
    "        solver=\"newton-cg\",\n",
    "        tol=1e-7,\n",
    "        random_state=42,\n",
    "    )\n",
    "    LRCV_auc_fit = LRCV_auc.fit(logit_model_vars[i], y_train)\n",
    "    # Calculate AUC on test for each fold\n",
    "    CV_AUC_folds[\"X\" + str(i + 1)] = LRCV_auc_fit.scores_[1][:, 0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c79ca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refit with AUC so we have AUC values for the same cv split\n",
    "logLasso_auc = LogisticRegressionCV(\n",
    "    Cs=C_values,\n",
    "    penalty=\"l1\",\n",
    "    cv=k,\n",
    "    refit=True,\n",
    "    scoring=\"roc_auc\",\n",
    "    solver=\"liblinear\",\n",
    "    random_state=42,\n",
    ")\n",
    "logLasso_auc_fitted = logLasso_auc.fit(normalized_logitvars, y_train)\n",
    "CV_AUC_folds[\"LASSO\"] = logLasso_auc_fitted.scores_[1][:, best_lambda_i].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8637627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each model: average RMSE and average AUC for models ----------------------------------\n",
    "CV_RMSE = dict()\n",
    "CV_AUC = dict()\n",
    "nvars = dict()\n",
    "\n",
    "for key in logit_models:\n",
    "    CV_RMSE[key] = np.mean(CV_RMSE_folds[key])\n",
    "    CV_AUC[key] = np.mean(CV_AUC_folds[key])\n",
    "\n",
    "for key in logit_models:\n",
    "    if key != \"LASSO\":\n",
    "        nvars[key] = logit_models[key].n_features_in_\n",
    "    else:\n",
    "        nvars[key] = sum(x != 0 for x in logit_models[key].coef_[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476a126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have 6 models, (5 logit and the logit lasso). For each we have a 5-CV RMSE and AUC.\n",
    "# We pick our preferred model based on that. -----------------------------------------------\n",
    "logit_summary1 = np.transpose(\n",
    "    pd.DataFrame.from_dict([nvars, CV_RMSE, CV_AUC], orient=\"columns\")\n",
    ")\n",
    "logit_summary1.columns = [\"Number of predictors\", \"CV RMSE\", \"CV AUC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a25111",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_summary1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd1dfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take best model and estimate RMSE on holdout  -------------------------------------------\n",
    "# X4, X5 and LASSO are practically the same - go with the simplest model\n",
    "\n",
    "best_model = logit_models[\"X4\"]\n",
    "best_model_X_holdout = X4.iloc[index_holdout]\n",
    "\n",
    "logit_predicted_probabilities_holdout = best_model.predict_proba(best_model_X_holdout)[\n",
    "    :, 1\n",
    "]\n",
    "best_rmse_holdout = np.sqrt(\n",
    "    metrics.mean_squared_error(y_holdout, logit_predicted_probabilities_holdout)\n",
    ")\n",
    "round(best_rmse_holdout, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cd0100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discrete ROC (with thresholds in steps) on holdout -------------------------------------------------\n",
    "\n",
    "thresholds = seq(0.05, 0.8, by=0.05)\n",
    "cm = dict()\n",
    "true_positive_rates = []\n",
    "false_positive_rates = []\n",
    "holdout_prediction = []\n",
    "for thr in thresholds:\n",
    "    holdout_prediction = np.where(logit_predicted_probabilities_holdout < thr, 0, 1)\n",
    "    cm_thr = confusion_matrix(y_holdout, holdout_prediction, labels=[0, 1])\n",
    "    cm[thr] = cm_thr\n",
    "    tn, fp, fn, tp = cm_thr.ravel()\n",
    "    true_positive_rates.append(tp / (tp + fn))\n",
    "    false_positive_rates.append(fp / (fp + tn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ad0c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr_fpr_for_thresholds = pd.DataFrame(\n",
    "    {\n",
    "        \"thresholds\": thresholds,\n",
    "        \"true_positive_rates\": true_positive_rates,\n",
    "        \"false_positive_rates\": false_positive_rates,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0c3bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(\n",
    "    tpr_fpr_for_thresholds,\n",
    "    aes(x=\"false_positive_rates\", y=\"true_positive_rates\", color=\"thresholds\"),\n",
    ") + labs(\n",
    "    x=\"False positive rate (1 - Specificity)\", y=\"True positive rate (Sensitivity)\"\n",
    ") + geom_point(\n",
    "    size=2, alpha=0.8\n",
    ") + scale_color_continuous(\n",
    "    trans=\"reverse\"\n",
    ") + scale_x_continuous(\n",
    "    limits=(0, 1), breaks=seq(0, 1.01, by=0.1)\n",
    ") + scale_y_continuous(\n",
    "    limits=(0, 1), breaks=seq(0, 1.01, by=0.1)\n",
    ") + theme_bw() + theme(\n",
    "    legend_position=\"right\",\n",
    "    axis_text=element_text(size=5),\n",
    "    axis_title=element_text(size=5),\n",
    "    legend_text=element_text(size=4),\n",
    "    legend_title=element_text(size=4),\n",
    "    legend_key_size=6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e2bbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# continuous ROC on holdout with best model (Logit 4) -------------------------------------------\n",
    "\n",
    "create_roc_plot(y_holdout, logit_predicted_probabilities_holdout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74741850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion table with different tresholds ----------------------------------------------------------\n",
    "\n",
    "# default: the threshold 0.5 is used to convert probabilities to binary classes\n",
    "logit_class_prediction = best_model.predict(best_model_X_holdout)\n",
    "\n",
    "values, counts = np.unique(logit_class_prediction.tolist(), return_counts=True)\n",
    "print(values[0], \" (no default): \", counts[0])\n",
    "print(values[1], \" (default): \", counts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24d7ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix: summarize different type of errors and successfully predicted cases\n",
    "# positive = \"yes\": explicitly specify the positive case\n",
    "cm_object1 = confusion_matrix(y_holdout, logit_class_prediction, labels=[0, 1])\n",
    "cm1 = pd.DataFrame(\n",
    "    cm_object1,\n",
    "    index=[\"Actul no defaul\", \"Actual default\"],\n",
    "    columns=[\"Predicted no default\", \"Predicted default\"],\n",
    ")\n",
    "cm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd50f3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can apply different thresholds\n",
    "\n",
    "# 0.5 same as before\n",
    "holdout_prediction = np.where(logit_predicted_probabilities_holdout < 0.5, 0, 1)\n",
    "cm_object1b = confusion_matrix(y_holdout, holdout_prediction, labels=[0, 1])\n",
    "cm1b = pd.DataFrame(\n",
    "    cm_object1b,\n",
    "    index=[\"Actul no defaul\", \"Actual default\"],\n",
    "    columns=[\"Predicted no default\", \"Predicted default\"],\n",
    ")\n",
    "cm1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f98d478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a sensible choice: mean of predicted probabilities\n",
    "mean_predicted_default_prob = np.mean(logit_predicted_probabilities_holdout)\n",
    "round(mean_predicted_default_prob, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0c3df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_prediction = np.where(\n",
    "    logit_predicted_probabilities_holdout < mean_predicted_default_prob, 0, 1\n",
    ")\n",
    "cm_object2 = confusion_matrix(y_holdout, holdout_prediction, labels=[0, 1])\n",
    "cm2 = pd.DataFrame(\n",
    "    cm_object2,\n",
    "    index=[\"Actul no defaul\", \"Actual default\"],\n",
    "    columns=[\"Predicted no default\", \"Predicted default\"],\n",
    ")\n",
    "cm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b14841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration curve -----------------------------------------------------------\n",
    "# how well do estimated vs actual event probabilities relate to each other?\n",
    "\n",
    "holdout = pd.concat([best_model_X_holdout, y_holdout], axis=1)\n",
    "holdout[\"best_logit_no_loss_pred\"] = logit_predicted_probabilities_holdout\n",
    "create_calibration_plot(\n",
    "    holdout,\n",
    "    file_name=\"ch17-figure-1-logit-m4-calibration\",\n",
    "    prob_var=\"best_logit_no_loss_pred\",\n",
    "    actual_var=\"default\",\n",
    "    y_lab=\"Actual event probability\",\n",
    "    n_bins=10,\n",
    "    breaks=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1699a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce loss function\n",
    "# relative cost of of a false negative classification (as compared with a false positive classification)\n",
    "FP = 1\n",
    "FN = 10\n",
    "cost = FN / FP\n",
    "# the prevalence, or the proportion of cases in the population (n.cases/(n.controls+n.cases))\n",
    "prevelance = y_train.sum() / len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb1f99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw ROC Curve and find optimal threshold with loss function --------------------------\n",
    "# The optimal cut-off is the threshold that maximizes the distance to the identity (diagonal) line\n",
    "\n",
    "best_thresholds_cv = dict()\n",
    "expected_loss_cv = dict()\n",
    "fold5_threshold = dict()\n",
    "fold5_expected_loss = dict()\n",
    "fold5_all_coords = dict()\n",
    "\n",
    "for i, model_name in enumerate(logit_models):\n",
    "    best_thresholds = []\n",
    "    expected_loss = []\n",
    "    if model_name != \"LASSO\":\n",
    "        X = logit_model_vars[i]\n",
    "        c_index = 0\n",
    "    else:\n",
    "        X = normalized_logitvars\n",
    "        c_index = best_lambda_i\n",
    "    fold = 0\n",
    "    for train_index, test_index in k.split(X):\n",
    "        X_fold = X.iloc[test_index, :]\n",
    "        y_fold = y_train.iloc[test_index]\n",
    "        pred_fold = generate_fold_prediction(\n",
    "            logit_models[model_name], X_fold, fold, c_index\n",
    "        )\n",
    "        false_pos_rate, true_pos_rate, thresholds = roc_curve(y_fold, pred_fold)\n",
    "        optimal_threshold = sorted(\n",
    "            list(\n",
    "                zip(\n",
    "                    np.abs(\n",
    "                        true_pos_rate\n",
    "                        + (1 - prevelance) / (cost * prevelance) * (1 - false_pos_rate)\n",
    "                    ),\n",
    "                    thresholds,\n",
    "                )\n",
    "            ),\n",
    "            key=lambda i: i[0],\n",
    "            reverse=True,\n",
    "        )[0][1]\n",
    "        best_thresholds.append(optimal_threshold)\n",
    "        threshold_prediction = np.where(pred_fold < optimal_threshold, 0, 1)\n",
    "        tn, fp, fn, tp = confusion_matrix(\n",
    "            y_fold, threshold_prediction, labels=[0, 1]\n",
    "        ).ravel()\n",
    "        curr_exp_loss = (fp * FP + fn * FN) / len(y_fold)\n",
    "        expected_loss.append(curr_exp_loss)\n",
    "        fold = fold + 1\n",
    "\n",
    "    best_thresholds_cv[model_name] = np.mean(best_thresholds)\n",
    "    expected_loss_cv[model_name] = np.mean(expected_loss)\n",
    "\n",
    "    # for fold #5\n",
    "    fold5_threshold[model_name] = optimal_threshold\n",
    "    fold5_expected_loss[model_name] = curr_exp_loss\n",
    "\n",
    "    all_coords = pd.DataFrame(\n",
    "        {\n",
    "            \"false_pos\": false_pos_rate * sum(y_fold == 0),\n",
    "            \"true_pos\": true_pos_rate * sum(y_fold == 1),\n",
    "            \"false_neg\": sum(y_fold == 1) - true_pos_rate * sum(y_fold == 1),\n",
    "            \"true_neg\": sum(y_fold == 0) - false_pos_rate * sum(y_fold == 0),\n",
    "            \"pos\": sum(y_fold == 1),\n",
    "            \"neg\": sum(y_fold == 0),\n",
    "            \"n\": len(y_fold),\n",
    "            \"thresholds\": thresholds,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    fold5_all_coords[model_name] = all_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c8d4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_summary2 = pd.DataFrame(\n",
    "    best_thresholds_cv.items(), columns=[\"Model\", \"Avg of optimal thresholds\"]\n",
    ")\n",
    "logit_summary2[\"Threshold for Fold5\"] = fold5_threshold.values()\n",
    "logit_summary2[\"Avg expected loss\"] = expected_loss_cv.values()\n",
    "logit_summary2[\"Expected loss for Fold5\"] = fold5_expected_loss.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff85819",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_summary2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f71b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create loss plot based on Fold5 in CV ----------------------------------------------\n",
    "# select model to plot\n",
    "model_to_plot = \"X1\"\n",
    "create_loss_plot(\n",
    "    fold5_all_coords[model_to_plot],\n",
    "    fold5_threshold[model_to_plot],\n",
    "    fold5_expected_loss[model_to_plot],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f3eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create roc plot plot based on Fold5 in CV ----------------------------------------------\n",
    "# select model to plot\n",
    "model_to_plot = \"X1\"\n",
    "create_roc_plot_with_optimal(\n",
    "    fold5_all_coords[model_to_plot], fold5_threshold[model_to_plot]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c298408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick best model based on average expected loss ----------------------------------\n",
    "# X4\n",
    "best_logit_optimal_treshold = best_thresholds_cv[\"X4\"]\n",
    "\n",
    "# Get expected loss on holdout\n",
    "holdout_treshold = np.where(\n",
    "    logit_predicted_probabilities_holdout < best_logit_optimal_treshold, 0, 1\n",
    ")\n",
    "tn, fp, fn, tp = confusion_matrix(y_holdout, holdout_treshold, labels=[0, 1]).ravel()\n",
    "expected_loss_holdout = (fp * FP + fn * FN) / len(y_holdout)\n",
    "round(expected_loss_holdout, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e597a8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_object3 = confusion_matrix(y_holdout, holdout_treshold, labels=[0, 1])\n",
    "cm3 = pd.DataFrame(\n",
    "    cm_object3,\n",
    "    index=[\"Actul no defaul\", \"Actual default\"],\n",
    "    columns=[\"Predicted no default\", \"Predicted default\"],\n",
    ")\n",
    "cm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6afbc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    \"max_features\": [5, 6, 7],\n",
    "    \"criterion\": [\"gini\"],\n",
    "    \"min_samples_split\": [11, 16],\n",
    "}  # 1 more than in R because here condition for min node size is >= while > in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52223910",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_forest = RandomForestClassifier(random_state=42, n_estimators=500, oob_score=True)\n",
    "prob_forest_grid = GridSearchCV(\n",
    "    prob_forest,\n",
    "    grid,\n",
    "    cv=k,\n",
    "    refit=\"accuracy\",\n",
    "    scoring=[\"accuracy\", \"roc_auc\", \"neg_brier_score\"],\n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f724d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_forest_fit = prob_forest_grid.fit(rfvars_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425b315d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create CV summary table\n",
    "cv_accuracy = np.zeros([6])\n",
    "for i in range(5):\n",
    "    cv_accuracy = (\n",
    "        cv_accuracy + prob_forest_fit.cv_results_[\"split\" + str(i) + \"_test_accuracy\"]\n",
    "    )\n",
    "cv_accuracy = cv_accuracy / 5\n",
    "\n",
    "cv_auc = np.zeros([6])\n",
    "for i in range(5):\n",
    "    cv_auc = cv_auc + prob_forest_fit.cv_results_[\"split\" + str(i) + \"_test_roc_auc\"]\n",
    "cv_auc = cv_auc / 5\n",
    "\n",
    "cv_rmse = np.zeros([6])\n",
    "for i in range(5):\n",
    "    cv_rmse = (\n",
    "        cv_rmse\n",
    "        + np.sqrt(\n",
    "            -1\n",
    "            * (prob_forest_fit.cv_results_[\"split\" + str(i) + \"_test_neg_brier_score\"])\n",
    "        ).tolist()\n",
    "    )\n",
    "cv_rmse = cv_rmse / 5\n",
    "\n",
    "prob_forest_cv_results = pd.DataFrame(\n",
    "    {\n",
    "        \"max_features\": prob_forest_fit.cv_results_[\"param_max_features\"],\n",
    "        \"min_samples_split\": prob_forest_fit.cv_results_[\"param_min_samples_split\"],\n",
    "        \"cv_accuracy\": cv_accuracy,\n",
    "        \"cv_auc\": cv_auc,\n",
    "        \"cv_rmse\": cv_rmse,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd654af",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_forest_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aea780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain optimal parameter values\n",
    "best_mtry = prob_forest_fit.best_params_[\"max_features\"]\n",
    "best_min_node_size = prob_forest_fit.best_params_[\"min_samples_split\"]\n",
    "prob_forest_fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff14024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average (ie over the folds) RMSE and AUC ------------------------------------\n",
    "prob_forest_best_results = prob_forest_cv_results[\n",
    "    (prob_forest_cv_results.max_features == best_mtry)\n",
    "    & (prob_forest_cv_results.min_samples_split == best_min_node_size)\n",
    "]\n",
    "prob_forest_best_results_index = prob_forest_best_results.index.values[0]\n",
    "\n",
    "CV_RMSE[\"rf_p\"] = prob_forest_best_results.cv_rmse.values[0]\n",
    "CV_AUC[\"rf_p\"] = prob_forest_best_results.cv_auc.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1af64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_RMSE_folds_rf_p = list()\n",
    "for i in range(5):\n",
    "    rmse = np.sqrt(\n",
    "        -1 * (prob_forest_fit.cv_results_[\"split\" + str(i) + \"_test_neg_brier_score\"])\n",
    "    ).tolist()[prob_forest_best_results_index]\n",
    "    CV_RMSE_folds_rf_p.append(rmse)\n",
    "CV_RMSE_folds[\"rf_p\"] = CV_RMSE_folds_rf_p\n",
    "\n",
    "CV_AUC_folds_rf_p = list()\n",
    "for i in range(5):\n",
    "    rmse = prob_forest_fit.cv_results_[\"split\" + str(i) + \"_test_roc_auc\"][\n",
    "        prob_forest_best_results_index\n",
    "    ]\n",
    "    CV_AUC_folds_rf_p.append(rmse)\n",
    "CV_AUC_folds[\"rf_p\"] = CV_AUC_folds_rf_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02976e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use loss function and search for best thresholds and expected loss over folds -----\n",
    "best_thresholds = list()\n",
    "expected_loss = list()\n",
    "\n",
    "fold = 0\n",
    "for train_index, test_index in k.split(rfvars_train):\n",
    "    X_fold = rfvars_train.iloc[test_index, :]\n",
    "    y_fold = y_train.iloc[test_index]\n",
    "\n",
    "    X_fold_train = rfvars_train.iloc[train_index, :]\n",
    "    y_fold_train = y_train.iloc[train_index]\n",
    "\n",
    "    prob_forest_best = RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        n_estimators=500,\n",
    "        oob_score=True,\n",
    "        criterion=\"gini\",\n",
    "        max_features=best_mtry,\n",
    "        min_samples_split=best_min_node_size,\n",
    "    )\n",
    "    prob_forest_best_fold = prob_forest_best.fit(X_fold_train, y_fold_train)\n",
    "    pred_fold = prob_forest_best_fold.predict_proba(X_fold)[:, 1]\n",
    "\n",
    "    false_pos_rate, true_pos_rate, threshold = roc_curve(y_fold, pred_fold)\n",
    "    best_threshold = sorted(\n",
    "        list(\n",
    "            zip(\n",
    "                np.abs(\n",
    "                    true_pos_rate\n",
    "                    + (1 - prevelance) / (cost * prevelance) * (1 - false_pos_rate)\n",
    "                ),\n",
    "                threshold,\n",
    "            )\n",
    "        ),\n",
    "        key=lambda x: x[0],\n",
    "        reverse=True,\n",
    "    )[0][1]\n",
    "    best_thresholds.append(best_threshold)\n",
    "    threshold_prediction = np.where(pred_fold < best_threshold, 0, 1)\n",
    "    tn, fp, fn, tp = confusion_matrix(\n",
    "        y_fold, threshold_prediction, labels=[0, 1]\n",
    "    ).ravel()\n",
    "    curr_exp_loss = (fp * FP + fn * FN) / len(y_fold)\n",
    "    expected_loss.append(curr_exp_loss)\n",
    "\n",
    "fold5_threshold_rf = best_threshold\n",
    "fold5_expected_loss_rf = curr_exp_loss\n",
    "\n",
    "all_coords_rf = pd.DataFrame(\n",
    "    {\n",
    "        \"false_pos\": false_pos_rate * sum(y_fold == 0),\n",
    "        \"true_pos\": true_pos_rate * sum(y_fold == 1),\n",
    "        \"false_neg\": sum(y_fold == 1) - true_pos_rate * sum(y_fold == 1),\n",
    "        \"true_neg\": sum(y_fold == 0) - false_pos_rate * sum(y_fold == 0),\n",
    "        \"pos\": sum(y_fold == 1),\n",
    "        \"neg\": sum(y_fold == 0),\n",
    "        \"n\": len(y_fold),\n",
    "        \"thresholds\": threshold,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be03d72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold5_threshold_rf = best_threshold\n",
    "fold5_expected_loss_rf = curr_exp_loss\n",
    "\n",
    "all_coords_rf = pd.DataFrame(\n",
    "    {\n",
    "        \"false_pos\": false_pos_rate * sum(y_fold == 0),\n",
    "        \"true_pos\": true_pos_rate * sum(y_fold == 1),\n",
    "        \"false_neg\": sum(y_fold == 1) - true_pos_rate * sum(y_fold == 1),\n",
    "        \"true_neg\": sum(y_fold == 0) - false_pos_rate * sum(y_fold == 0),\n",
    "        \"pos\": sum(y_fold == 1),\n",
    "        \"neg\": sum(y_fold == 0),\n",
    "        \"n\": len(y_fold),\n",
    "        \"thresholds\": threshold,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18a5895",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_loss_cv[\"rf_p\"] = np.mean(expected_loss)\n",
    "best_thresholds_cv[\"rf_p\"] = np.mean(best_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b03f9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_summary = pd.DataFrame(\n",
    "    {\n",
    "        \"CV RMSE\": [round(CV_RMSE[\"rf_p\"], 3)],\n",
    "        \"CV AUC\": [round(CV_AUC[\"rf_p\"], 3)],\n",
    "        \"Avg of optimal thresholds\": [round(best_thresholds_cv[\"rf_p\"], 3)],\n",
    "        \"Threshold for Fold5\": [round(best_threshold, 3)],\n",
    "        \"Avg expected loss\": [round(expected_loss_cv[\"rf_p\"], 3)],\n",
    "        \"Expected loss for Fold5\": [round(curr_exp_loss, 3)],\n",
    "    }\n",
    ")\n",
    "\n",
    "rf_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bff699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots based on Fold5 in CV ----------------------------------------------\n",
    "create_loss_plot(all_coords_rf, fold5_threshold_rf, fold5_expected_loss_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c34c57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_roc_plot_with_optimal(all_coords_rf, fold5_threshold_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fbb279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take model to holdout and estimate RMSE, AUC and expected loss ------------------------------------\n",
    "prob_forest_fit_best = prob_forest_fit.best_estimator_\n",
    "rf_predicted_probabilities_holdout = prob_forest_fit_best.predict_proba(rfvars_holdout)[\n",
    "    :, 1\n",
    "]\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_holdout, rf_predicted_probabilities_holdout))\n",
    "round(rmse_rf, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1c094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC AUC  on holdout\n",
    "auc_rf = roc_auc_score(y_holdout, rf_predicted_probabilities_holdout)\n",
    "round(auc_rf, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b632a8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get expected loss on holdout\n",
    "holdout_treshold = np.where(\n",
    "    rf_predicted_probabilities_holdout < best_thresholds_cv[\"rf_p\"], 0, 1\n",
    ")\n",
    "tn, fp, fn, tp = confusion_matrix(y_holdout, holdout_treshold, labels=[0, 1]).ravel()\n",
    "expected_loss_holdout = (fp * FP + fn * FN) / len(y_holdout)\n",
    "round(expected_loss_holdout, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6b4c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvars['rf_p'] = len(rfvars.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8523ae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_results = pd.DataFrame(\n",
    "    {\n",
    "        \"Model\": list(nvars.keys()),\n",
    "        \"Number of predictors\": list(nvars.values()),\n",
    "        \"CV RMSE\": list(CV_RMSE.values()),\n",
    "        \"CV AUC\": list(CV_AUC.values()),\n",
    "        \"CV threshold\": list(best_thresholds_cv.values()),\n",
    "        \"CV expected Loss\": list(expected_loss_cv.values()),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21a7bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4250ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
